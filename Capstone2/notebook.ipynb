{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109698a2",
   "metadata": {},
   "source": [
    "# Face Mask Image Classification – Capstone 2\n",
    "\n",
    "## Objective\n",
    "The goal of this project is to build a deep learning image classification model\n",
    "to detect whether a person is wearing a face mask or not.\n",
    "\n",
    "This notebook focuses on:\n",
    "- Dataset exploration (EDA for images)\n",
    "- Data quality checks\n",
    "- Baseline model training\n",
    "- Model evaluation\n",
    "\n",
    "Production deployment, monitoring, and Kubernetes orchestration\n",
    "are implemented separately in scripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d7b18",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ca303",
   "metadata": {},
   "source": [
    "### Dataset Structure Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    print(f\"\\n{split.upper()} SET\")\n",
    "    for cls in os.listdir(os.path.join(DATA_DIR, split)):\n",
    "        n = len(os.listdir(os.path.join(DATA_DIR, split, cls)))\n",
    "        print(f\"{cls}: {n} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b11e2c",
   "metadata": {},
   "source": [
    "### Visualize Sample Images (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(folder, n=5):\n",
    "    images = random.sample(os.listdir(folder), n)\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, img in enumerate(images):\n",
    "        path = os.path.join(folder, img)\n",
    "        image = plt.imread(path)\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"MASK examples\")\n",
    "show_images(\"data/train/mask\")\n",
    "\n",
    "print(\"NO MASK examples\")\n",
    "show_images(\"data/train/no_mask\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b2ad3",
   "metadata": {},
   "source": [
    "### Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb62d3e",
   "metadata": {},
   "source": [
    "### Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae32f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.ImageFolder(\"data/train\", transform=train_transform)\n",
    "val_ds = datasets.ImageFolder(\"data/val\", transform=val_transform)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "class_names = train_ds.classes\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befb582",
   "metadata": {},
   "source": [
    "### Model Definition (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f72411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1a6a6",
   "metadata": {},
   "source": [
    "### Training Loop (Short, Notebook-only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b532b",
   "metadata": {},
   "source": [
    "⚠️ Important:\n",
    "\n",
    "This is for validation only.\n",
    "\n",
    "Final training happens in train.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873fadb",
   "metadata": {},
   "source": [
    "### Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            targets.extend(y.numpy())\n",
    "\n",
    "    return preds, targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4349c2",
   "metadata": {},
   "source": [
    "### Train for a Few Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    loss = train_one_epoch(model, train_dl)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440d532",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53793a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets = evaluate(model, val_dl)\n",
    "\n",
    "print(classification_report(targets, preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b6190",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets, preds)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.xticks([0,1], class_names)\n",
    "plt.yticks([0,1], class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3d862",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- The dataset is balanced enough for binary classification.\n",
    "- The model converges quickly using transfer learning.\n",
    "- Most misclassifications occur in partially occluded faces.\n",
    "- The trained model is suitable for deployment as an inference service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14b6a6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook validated the feasibility of a CNN-based approach\n",
    "for face mask classification.\n",
    "\n",
    "The final system is deployed using:\n",
    "- FastAPI for inference\n",
    "- Docker for containerization\n",
    "- Kubernetes (kind) for orchestration\n",
    "- Monitoring for prediction drift\n",
    "\n",
    "Training and serving logic are separated from this notebook\n",
    "to ensure reproducibility and production readiness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
